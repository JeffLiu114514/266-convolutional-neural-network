{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "effa8ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.functional import accuracy\n",
    "import torchmetrics\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import resnet50, ResNet50_Weights, swin_t, Swin_T_Weights\n",
    "# from models import FineTuningModel\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch.optim as optim\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48b1586c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data'\n",
    "batch_size = 32\n",
    "num_classes = 37\n",
    "max_epochs = 10\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#The images are resized to resize_size=[256] using interpolation=InterpolationMode.BILINEAR, followed by a central crop \n",
    "#of crop_size=[224]. Finally the values are first rescaled to [0.0, 1.0] and then normalized using mean=[0.485, 0.456, 0.406] \n",
    "#and std=[0.229, 0.224, 0.225].\n",
    "resnet_train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(232, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "resnet_test_transforms = transforms.Compose([\n",
    "    transforms.Resize(232, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "resnet_train_dataset = torchvision.datasets.OxfordIIITPet(root = './data',\n",
    "                                             split = 'trainval',\n",
    "                                             transform = resnet_train_transforms,\n",
    "                                             download = True)\n",
    "\n",
    "resnet_test_dataset = torchvision.datasets.OxfordIIITPet(root = './data',\n",
    "                                            split = 'test',\n",
    "                                            transform = resnet_test_transforms,\n",
    "                                            download=True)\n",
    "\n",
    "resnet_train_loader = torch.utils.data.DataLoader(dataset = resnet_train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True,\n",
    "                                           num_workers = 4)\n",
    "\n",
    "\n",
    "resnet_test_loader = torch.utils.data.DataLoader(dataset = resnet_test_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = False,\n",
    "                                           num_workers = 4)\n",
    "\n",
    "#The images are resized to resize_size=[232] using interpolation=InterpolationMode.BICUBIC, followed by a central crop \n",
    "#of crop_size=[224]. Finally the values are first rescaled to [0.0, 1.0] and then normalized using mean=[0.485, 0.456, 0.406] \n",
    "#and std=[0.229, 0.224, 0.225].\n",
    "swin_train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(232, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "swin_test_transforms = transforms.Compose([\n",
    "    transforms.Resize(232, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "swin_train_dataset = torchvision.datasets.OxfordIIITPet(root = './data',\n",
    "                                             split = 'trainval',\n",
    "                                             transform = swin_train_transforms,\n",
    "                                             download = True)\n",
    "\n",
    "swin_test_dataset = torchvision.datasets.OxfordIIITPet(root = './data',\n",
    "                                            split = 'test',\n",
    "                                            transform = swin_test_transforms,\n",
    "                                            download=True)\n",
    "\n",
    "swin_train_loader = torch.utils.data.DataLoader(dataset = swin_train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True,\n",
    "                                           num_workers = 4)\n",
    "\n",
    "\n",
    "swin_test_loader = torch.utils.data.DataLoader(dataset = swin_test_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = False,\n",
    "                                           num_workers = 4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33f45de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FineTuningModel(pl.LightningModule):\n",
    "    def __init__(self, backbone, num_classes, model):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Replace the output layer with a new fully connected layer\n",
    "        if model == \"resnet\":\n",
    "            num_features = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Linear(num_features, num_classes)\n",
    "        elif model == \"swin\":\n",
    "            num_features = self.backbone.head.in_features\n",
    "            self.backbone.head = nn.Linear(num_features, num_classes)\n",
    "\n",
    "        # Define the loss function\n",
    "        self.loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        train_loss = self.loss_function(y_hat, y)\n",
    "        prediction = torch.argmax(y_hat, dim=1)\n",
    "        correct = torch.sum(y == prediction).item()\n",
    "        tensorboard_logs = {'train_acc_step': correct, 'train_loss_step': train_loss}\n",
    "\n",
    "        return {'loss': train_loss, \"correct\": correct, \"prediction_length\": len(y), 'log': tensorboard_logs}\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "\n",
    "        train_accuracy = sum([x['correct'] for x in outputs]) / sum(x['prediction_length'] for x in outputs)\n",
    "        # tensorboard_logs = {'train_accuracy': train_accuracy, 'train_loss': avg_loss, 'step': self.current_epoch}\n",
    "        self.log('step', self.trainer.current_epoch)\n",
    "        self.log('train_loss', avg_loss, logger=True, prog_bar=True, on_epoch=True, on_step=False)\n",
    "        self.log('train_accuracy', train_accuracy, logger=True, prog_bar=True, on_epoch=True, on_step=False)\n",
    "        # return {'loss': avg_loss, 'log': tensorboard_logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        test_loss = self.loss_function(y_hat, y)\n",
    "        prediction = torch.argmax(y_hat, dim=1)\n",
    "        correct = torch.sum(y == prediction).item()\n",
    "        # self.log('val_loss', test_loss)\n",
    "        return {'val_loss': test_loss, \"correct\": correct, \"prediction_length\": len(y)}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "\n",
    "        val_acc = sum([x['correct'] for x in outputs]) / sum(x['prediction_length'] for x in outputs)\n",
    "        # tensorboard_logs = {'val_loss': avg_loss, 'val_acc': val_acc, 'step': self.current_epoch}\n",
    "        self.log('step', self.trainer.current_epoch)\n",
    "        self.log('val_loss', avg_loss, logger=True, prog_bar=True, on_epoch=True, on_step=False)\n",
    "        self.log('val_acc', val_acc, logger=True, prog_bar=True, on_epoch=True, on_step=False)\n",
    "         \n",
    "        # return {'log': tensorboard_logs}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters())\n",
    "        return optimizer\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6308a267",
   "metadata": {},
   "source": [
    "## Fine-tune output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe34de62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | backbone      | ResNet           | 23.6 M\n",
      "1 | loss_function | CrossEntropyLoss | 0     \n",
      "---------------------------------------------------\n",
      "75.8 K    Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.6 M    Total params\n",
      "94.335    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23566\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x0000021A294604C0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\23566\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"C:\\Users\\23566\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1424, in _shutdown_workers\n",
      "    if self._persistent_workers or self._workers_status[worker_id]:\n",
      "AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune ResNet-50\n",
    "resnet_output = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "for param in resnet_output.parameters():\n",
    "    param.requires_grad = False\n",
    "resnet_output.fc.requires_grad_(True)\n",
    "resnet_model_1 = FineTuningModel(backbone=resnet_output, num_classes=num_classes, model=\"resnet\")\n",
    "\n",
    "resnet_output_logger = TensorBoardLogger('logs', name='resnet_output_logger')\n",
    "trainer = pl.Trainer(accelerator='gpu', max_epochs=max_epochs, logger=resnet_output_logger)\n",
    "trainer.fit(resnet_model_1, resnet_train_loader, resnet_test_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a134f0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | backbone      | SwinTransformer  | 27.5 M\n",
      "1 | loss_function | CrossEntropyLoss | 0     \n",
      "---------------------------------------------------\n",
      "28.5 K    Trainable params\n",
      "27.5 M    Non-trainable params\n",
      "27.5 M    Total params\n",
      "110.191   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x0000021A294604C0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\23566\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"C:\\Users\\23566\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1424, in _shutdown_workers\n",
      "    if self._persistent_workers or self._workers_status[worker_id]:\n",
      "AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune Swin-T\n",
    "swin_output = swin_t(weights=Swin_T_Weights.DEFAULT)\n",
    "for param in swin_output.parameters():\n",
    "    param.requires_grad = False\n",
    "swin_output.head.requires_grad_(True)\n",
    "swin_model_1 = FineTuningModel(backbone=swin_output, num_classes=num_classes, model=\"swin\")\n",
    "\n",
    "swin_output_logger = TensorBoardLogger('logs', name='swin_output_logger')\n",
    "trainer = pl.Trainer(accelerator='gpu', max_epochs=max_epochs, logger=swin_output_logger)\n",
    "trainer.fit(swin_model_1, swin_train_loader, swin_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acef2037",
   "metadata": {},
   "source": [
    "## Fine-tune all units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0c4d2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | backbone      | ResNet           | 23.6 M\n",
      "1 | loss_function | CrossEntropyLoss | 0     \n",
      "---------------------------------------------------\n",
      "23.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.6 M    Total params\n",
      "94.335    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fine-tune ResNet-50\n",
    "resnet_all = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "#for param in resnet_all.parameters():\n",
    "#    param.requires_grad = True\n",
    "# resnet_all.fc.requires_grad_(True)\n",
    "resnet_model_2 = FineTuningModel(backbone=resnet_all, num_classes=num_classes, model=\"resnet\")\n",
    "\n",
    "resnet_all_logger = TensorBoardLogger('logs', name='resnet_all_logger')\n",
    "trainer = pl.Trainer(accelerator='gpu', max_epochs=max_epochs, logger=resnet_all_logger)\n",
    "trainer.fit(resnet_model_2, resnet_train_loader, resnet_test_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eba22f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | backbone      | SwinTransformer  | 27.5 M\n",
      "1 | loss_function | CrossEntropyLoss | 0     \n",
      "---------------------------------------------------\n",
      "27.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "27.5 M    Total params\n",
      "110.191   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23566\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\result.py:232: UserWarning: You called `self.log('step', ...)` in your `validation_epoch_end` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac665714d7d840e692af4b14f3db0920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23566\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\result.py:232: UserWarning: You called `self.log('step', ...)` in your `training_epoch_end` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune Swin-T\n",
    "swin_all = swin_t(weights=Swin_T_Weights.DEFAULT)\n",
    "for param in swin_all.parameters():\n",
    "    param.requires_grad = True\n",
    "swin_all.head.requires_grad_(True)\n",
    "swin_model_2 = FineTuningModel(backbone=swin_all, num_classes=num_classes, model=\"swin\")\n",
    "\n",
    "swin_all_logger = TensorBoardLogger('logs', name='swin_all_logger')\n",
    "trainer = pl.Trainer(accelerator='gpu', max_epochs=max_epochs, logger=swin_all_logger)\n",
    "trainer.fit(swin_model_2, swin_train_loader, swin_test_loader)\n",
    "\n",
    "# tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da58f18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "f73feade3c41b07c778433e3ea41bf19ee3219790be6b5226795e193e1a72173"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
